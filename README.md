# Распознавание корейских букв с помощью CNN

Проект для обучения сверточной нейронной сети (CNN) на PyTorch для распознавания корейских букв: ㄱ, ㄴ, ㄷ, ㄹ, ㅁ из изображений, включая рукописный ввод.

## Требования

- Python 3.10 или выше
- Windows OS
- NVIDIA GPU с поддержкой CUDA (опционально, но рекомендуется)
- Виртуальное окружение (venv)

## Установка

### 1. Создание виртуального окружения

Откройте PowerShell или командную строку в директории проекта и выполните:

```powershell
python -m venv venv
```

### 2. Активация виртуального окружения

В PowerShell:
```powershell
.\venv\Scripts\Activate.ps1
```

Если возникнет ошибка политики выполнения, выполните:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

В командной строке (cmd):
```cmd
venv\Scripts\activate.bat
```

### 3. Установка зависимостей

```powershell
pip install -r requirements.txt
```

## Запуск

### STEP 0 - Проверка работоспособности

После установки зависимостей выполните:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Сообщение "Training pipeline initialized"
- Информация о доступности CUDA/GPU
- Успешное завершение без ошибок

### STEP 1 - Configuration & Utilities

Запуск аналогичен STEP 0:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Инициализация пайплайна обучения
- Установка seed для воспроизводимости
- Информация о доступности GPU/CUDA
- Информация о классах для распознавания (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ)
- Успешное завершение с сообщением "STEP 1 завершен успешно!"

### STEP 2 - Dataset Discovery & Download

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из STEP 0 и STEP 1
- Инициализация датасета
- Размер датасета (пока используется 1000 dummy сэмплов)
- Размер изображений (28x28)
- Пример сэмпла (shape и метка класса)
- Успешное завершение с сообщением "STEP 2 завершен успешно!"

## Структура проекта

```
project/
├── data/
│   ├── raw/          # Исходные данные
│   └── processed/    # Обработанные данные
├── models/           # Сохраненные модели
├── src/
│   ├── __init__.py
│   ├── config.py     # Конфигурация проекта
│   ├── dataset.py    # Работа с датасетом
│   ├── model.py      # Архитектура CNN
│   ├── train.py      # Обучение модели
│   ├── predict.py    # Предсказания
│   └── utils.py      # Вспомогательные функции
├── ui/               # Пользовательский интерфейс (будет добавлено)
├── requirements.txt
└── README.md
```

## Текущий статус

- **STEP 0** ✅ - Проект инициализирован, базовая структура создана
- **STEP 1** ✅ - Реализованы конфигурация и утилиты:
  - Централизованная конфигурация (`config.py`): пути, метки классов, выбор устройства
  - Вспомогательные утилиты (`utils.py`): установка seed, логирование
  - Обновлен `train.py` для использования config и utils
- **STEP 2** ✅ - Реализована логика работы с датасетом:
  - Класс `KoreanAlphabetDataset` для работы с данными
  - Функция `download_dataset()` для загрузки датасета (пока placeholder)
  - Поддержка dummy данных для тестирования (1000 сэмплов)
  - Интеграция датасета в `train.py`

## Следующие шаги

- STEP 3: Создание архитектуры CNN
- STEP 4: Реализация обучения
- STEP 5: Визуализация результатов
- STEP 6: Предсказания на новых данных
- STEP 7: Интеграция реального датасета (замена dummy данных)

## Детали реализации

### STEP 1 - Configuration & Utilities

**config.py:**
- Определение путей проекта (data/, models/, etc.)
- Метки классов: `CLASS_LABELS = ["ㄱ", "ㄴ", "ㄷ", "ㄹ", "ㅁ"]`
- Словари для преобразования между метками и индексами
- Функция `get_device()` для автоматического определения CUDA/CPU

**utils.py:**
- `set_seed(seed=42)` - установка seed для воспроизводимости (Python, NumPy, PyTorch, CUDA)
- Функции логирования: `log_info()`, `log_warning()`, `log_error()`

### STEP 2 - Dataset Discovery & Download

**dataset.py:**
- Класс `KoreanAlphabetDataset`, наследующийся от `torch.utils.data.Dataset`
- Функция `download_dataset()` - placeholder для загрузки реального датасета
- Поддержка dummy данных (случайные изображения 28x28) для тестирования структуры
- Методы `__len__()` и `__getitem__()` для работы с данными
- Метод `get_class_name()` для получения метки класса по индексу
- TODO маркеры для будущей интеграции реальных данных

**config.py (обновлено):**
- Параметры датасета: `IMAGE_SIZE = (28, 28)`, `DEFAULT_NUM_SAMPLES = 1000`

**Примечание:** В настоящее время используются dummy данные для проверки работоспособности структуры. После получения реального датасета (например, Hangul Fonts Dataset или KMNIST) необходимо будет обновить метод `__getitem__()` в классе `KoreanAlphabetDataset`.

## Примечания

- Все комментарии и объяснения на русском языке
- Код разрабатывается инкрементально, каждый шаг должен быть выполнимым
- Модели автоматически сохраняются в директорию `models/`
- Проект автоматически определяет доступность GPU и использует CPU при необходимости
- Seed устанавливается автоматически для обеспечения воспроизводимости результатов

