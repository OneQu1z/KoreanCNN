# Распознавание корейских букв с помощью CNN

Проект для обучения сверточной нейронной сети (CNN) на PyTorch для распознавания корейских букв: ㄱ, ㄴ, ㄷ, ㄹ, ㅁ из изображений, включая рукописный ввод.

## Требования

- Python 3.10 или выше
- Windows OS
- NVIDIA GPU с поддержкой CUDA (опционально, но рекомендуется)
- Виртуальное окружение (venv)

## Установка

### 1. Создание виртуального окружения

Откройте PowerShell или командную строку в директории проекта и выполните:

```powershell
python -m venv venv
```

### 2. Активация виртуального окружения

В PowerShell:
```powershell
.\venv\Scripts\Activate.ps1
```

Если возникнет ошибка политики выполнения, выполните:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

В командной строке (cmd):
```cmd
venv\Scripts\activate.bat
```

### 3. Установка зависимостей

```powershell
pip install -r requirements.txt
```

## Обучение модели

Для обучения модели выполните:

```powershell
python -m src.train
```

Этот скрипт выполняет все этапы обучения:
- Генерацию датасета (если его еще нет)
- Разделение на train/validation наборы
- Обучение CNN модели
- Сохранение лучшей модели в директорию `models/`
- Сохранение графиков метрик в директорию `plots/`

Модель будет обучена до достижения целевой accuracy (100% по умолчанию) или максимального количества эпох (50).

### STEP 0 - Проверка работоспособности

После установки зависимостей выполните:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Сообщение "Training pipeline initialized"
- Информация о доступности CUDA/GPU
- Успешное завершение без ошибок

### STEP 1 - Configuration & Utilities

Запуск аналогичен STEP 0:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Инициализация пайплайна обучения
- Установка seed для воспроизводимости
- Информация о доступности GPU/CUDA
- Информация о классах для распознавания (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ)
- Успешное завершение с сообщением "STEP 1 завершен успешно!"

### STEP 2 - Dataset Discovery & Download

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из STEP 0 и STEP 1
- Инициализация датасета
- Размер датасета (пока используется 1000 dummy сэмплов)
- Размер изображений (28x28)
- Пример сэмпла (shape и метка класса)
- Успешное завершение с сообщением "STEP 2 завершен успешно!"

### STEP 3 - Real Dataset Preprocessing

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Автоматическая генерация реальных изображений корейских букв (если датасет отсутствует)
- Загрузка 1000 реальных изображений (200 для каждого класса)
- Разделение на train/validation (800/200 сэмплов)
- Создание DataLoader'ов для обучения и валидации
- Вывод формы батча: `torch.Size([32, 1, 28, 28])` - 32 изображения, 1 канал (grayscale), 28x28 пикселей
- Нормализация изображений в диапазон [-1, 1]
- Успешное завершение с сообщением "STEP 3 завершен успешно!"

### STEP 4 - CNN Model

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Создание CNN модели (KoreanAlphabetCNN)
- Информация о количестве параметров модели (~206,000)
- Тестирование forward pass на одном батче
- Вывод формы выходного тензора: `torch.Size([32, 5])` - 32 предсказания для 5 классов
- Успешное завершение с сообщением "STEP 4 завершен успешно!"

### STEP 5 - Training Loop

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Настройка обучения (CrossEntropyLoss, Adam optimizer)
- Процесс обучения до достижения целевой accuracy (100%) или максимального количества эпох
- Вывод статистики после каждой эпохи (Loss и Accuracy)
- Сохранение лучшей модели при улучшении accuracy
- Автоматическая остановка при достижении целевой accuracy
- Успешное завершение с сообщением "STEP 5 завершен успешно!"

**Пример результата:** Модель обычно достигает 100% validation accuracy за 8-11 эпох

### STEP 6 - Metrics & Visualization

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Создание графиков метрик обучения после завершения обучения
- Сохранение графиков в директорию `plots/`
- Графики содержат:
  - Loss по эпохам (train и validation)
  - Accuracy по эпохам (train и validation)
- Успешное завершение с сообщением "STEP 6 завершен успешно!"

## Структура проекта

```
project/
├── data/
│   ├── raw/              # Исходные данные
│   │   ├── ㄱ/          # Изображения класса ㄱ
│   │   ├── ㄴ/          # Изображения класса ㄴ
│   │   ├── ㄷ/          # Изображения класса ㄷ
│   │   ├── ㄹ/          # Изображения класса ㄹ
│   │   └── ㅁ/          # Изображения класса ㅁ
│   └── processed/        # Обработанные данные
├── models/               # Сохраненные модели
├── plots/                # Графики метрик обучения
├── src/
│   ├── __init__.py
│   ├── config.py         # Конфигурация проекта
│   ├── dataset.py        # Интерфейс для работы с датасетом
│   ├── datasets/         # Модули для работы с данными
│   │   ├── __init__.py
│   │   └── font_based.py    # Генерация через корейские шрифты
│   ├── model.py          # Архитектура CNN
│   ├── train.py          # Обучение модели
│   ├── predict.py        # Предсказания
│   └── utils.py          # Вспомогательные функции
├── ui/                   # Пользовательский интерфейс
│   └── app.py           # Streamlit веб-приложение
├── app_desktop.py       # Desktop приложение (CustomTkinter)
├── ui_gradio.py         # Альтернативный UI на Gradio (опционально)
├── requirements.txt     # Зависимости проекта
└── README.md            # Документация
```

## Источник данных

Проект использует генерацию изображений корейских букв через корейские шрифты, установленные в системе Windows.

### Автоматическая генерация датасета

При первом запуске обучения (`python -m src.train`) проект автоматически:
1. Проверяет наличие установленных корейских шрифтов в системе
2. Генерирует изображения для каждой буквы (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ) используя различные шрифты
3. Сохраняет изображения в директорию `data/raw/<класс>/`
4. Каждый класс содержит 200 изображений по умолчанию

**Формат файлов:** `{класс}_{шрифт}_{номер}.png` (например, `ㄱ_NanumGothic-Regular_0000.png`)

### Требования к шрифтам

Для работы проекта необходимо установить корейские шрифты в системе Windows. Проект автоматически ищет следующие шрифты в директории `C:/Windows/Fonts/`:

- BlackAndWhitePicture-Regular
- ChosunIlboMyeongjo
- GamjaFlower-Regular
- GothicA1 (различные варианты: Black, Bold, ExtraBold, ExtraLight, Light, Medium, Regular, SemiBold, Thin)
- HiMelody-Regular
- IropkeBatangM
- NanumBarunGothic, NanumBarunGothic-UltraLight
- NanumBarunPen-Regular
- NanumBrushScript-Regular
- NanumGothic (Bold, ExtraBold, Regular)
- NanumGothicCoding (Bold, Regular)
- NanumMyeongjo (Bold, ExtraBold, Regular)
- NanumPenScript-Regular
- PoorStory-Regular
- SeoulHangang (B, BL, EB, L, M)
- SourceHanSerifK-Regular
- Stylish-Regular

**Характеристики генерируемых изображений:**
- Размер: 28x28 пикселей
- Формат: Grayscale (оттенки серого)
- Вариации размера шрифта: 20-26 пикселей
- Нормализация: значения в диапазоне [-1, 1]
- Автоматическое центрирование: содержимое центрируется в кадре

## Текущий статус

- **STEP 0** ✅ - Проект инициализирован, базовая структура создана
- **STEP 1** ✅ - Реализованы конфигурация и утилиты:
  - Централизованная конфигурация (`config.py`): пути, метки классов, выбор устройства
  - Вспомогательные утилиты (`utils.py`): установка seed, логирование
  - Обновлен `train.py` для использования config и utils
- **STEP 2** ✅ - Реализована логика работы с датасетом:
  - Класс `KoreanAlphabetDataset` для работы с данными
  - Функция `download_dataset()` для загрузки датасета (пока placeholder)
  - Поддержка dummy данных для тестирования (1000 сэмплов)
  - Интеграция датасета в `train.py`
- **STEP 3** ✅ - Реализована предобработка реальных данных:
  - Генерация изображений через корейские шрифты, установленные в системе
  - Поддержка 35+ корейских шрифтов для разнообразия данных
  - Автоматическое обнаружение доступных шрифтов
  - Предобработка: изменение размера до 28x28, преобразование в grayscale, нормализация
  - Разделение данных на train/validation (80%/20%)
  - Создание DataLoader'ов для батчевой загрузки
  - Проверка и вывод формы батчей
- **STEP 4** ✅ - Реализована CNN модель:
  - Архитектура: 2 сверточных слоя (Conv2d) + 2 полносвязных слоя (Linear)
  - Активации ReLU, MaxPooling для уменьшения размерности
  - Модель для классификации 5 классов корейских букв
  - Forward pass протестирован и работает корректно
  - Модель автоматически размещается на GPU при наличии CUDA
- **STEP 5** ✅ - Реализован цикл обучения:
  - Функция потерь: CrossEntropyLoss
  - Оптимизатор: Adam (learning rate = 0.001)
  - Обучение до достижения целевой accuracy (100%) или максимального количества эпох (50)
  - Вычисление и вывод Loss и Accuracy после каждой эпохи (train и validation)
  - Сохранение лучшей модели при улучшении accuracy (по validation accuracy)
  - Ранняя остановка при достижении целевой accuracy
  - Модель сохраняется с timestamp, accuracy в имени файла и метаданными
- **STEP 6** ✅ - Реализована визуализация метрик:
  - Отслеживание истории loss и accuracy для train и validation наборов
  - Построение графиков с помощью matplotlib
  - Графики loss и accuracy по эпохам
  - Автоматическое сохранение графиков в директорию `plots/`
  - Высокое качество сохранения (DPI 300)
- **STEP 7** ✅ - Реализован скрипт предсказаний:
  - Загрузка сохраненной модели (автоматически находит последнюю или по указанному пути)
  - Загрузка и предобработка изображения (resize, grayscale, normalize)
  - Выполнение inference на модели
  - Вывод предсказанной буквы и уверенности
  - Вывод вероятностей для всех классов
  - Безопасные проверки (существование файлов, обработка ошибок)
  - Читаемый вывод с форматированием
- **STEP 8** ✅ - Реализован простой браузерный UI:
  - Web-интерфейс на Streamlit
  - Два режима работы:
    - **Загрузка файла**: загрузка изображений через drag-and-drop или выбор файла
    - **Рисование**: интерактивное рисование буквы прямо в браузере (рукописный ввод)
  - Выбор модели из списка доступных
  - Визуализация результатов с графиками вероятностей
  - Информация о модели и рекомендации
  - Настройки рисования (толщина линии, цвет)
  - Не требует внешних сетевых подключений (работает локально)
- **STEP 9** ✅ - Очистка и документация:
  - Полная документация проекта
  - Инструкции по обучению, использованию и предсказаниям
  - Описание всех компонентов и способов использования
  - Desktop приложение как основной способ использования

## Использование

### Предсказания через командную строку

Для распознавания буквы на изображении через командную строку:

```powershell
python -m src.predict --image путь/к/изображению.png
```

Или с указанием конкретной модели:

```powershell
python -m src.predict --image путь/к/изображению.png --model models/название_модели.pth
```

**Примеры:**
```powershell
# Использование последней модели
python -m src.predict --image data/raw/ㄱ/ㄱ_NanumGothic-Regular_0000.png

# Использование конкретной модели
python -m src.predict --image src/image.png --model models/korean_cnn_best_epoch9_train99.8%_val100.0%_20251223_204342.pth
```

**Результат:**
- Предсказанная буква
- Уверенность (процент)
- Вероятности для всех классов (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ)

### Desktop приложение (Рекомендуется)

Для удобного использования доступно desktop приложение с графическим интерфейсом:

```powershell
python app_desktop.py
```

**Возможности:**
- Современный интерфейс на CustomTkinter (темная тема)
- Загрузка изображений через файловый диалог
- Предпросмотр загруженного изображения
- Выбор модели из списка доступных
- Отображение результатов распознавания с вероятностями для всех классов
- Информация о загруженной модели (эпоха, accuracy)

**Интерфейс:**
- Левая панель: настройки модели (выбор модели, статус, информация)
- Правая панель: загрузка изображений и результаты распознавания

### Веб-интерфейс (Streamlit)

Альтернативный веб-интерфейс на Streamlit:

```powershell
streamlit run ui/app.py
```

Приложение откроется в браузере по адресу `http://localhost:8501`.

**Функции:**
- **Вкладка "Загрузка файла"**: Загрузите готовое изображение корейской буквы
- **Вкладка "Рисование"**: Интерактивное рисование буквы прямо в браузере
  - Настройка толщины линии (1-20 пикселей)
  - Выбор цвета линии
  - Кнопка очистки холста
- Выбор модели из списка доступных
- Визуализация результатов с графиками вероятностей

## Рекомендации по использованию

### Для лучшего распознавания:

1. **Качество изображения:**
   - Используйте четкие, контрастные изображения
   - Буква должна быть хорошо видна на фоне
   - Размер изображения не критичен (автоматически масштабируется)

2. **Предобработка:**
   - Изображения автоматически конвертируются в grayscale
   - Автоматическое центрирование содержимого
   - Нормализация значений

3. **Стиль букв:**
   - Модель обучена на шрифтовых изображениях
   - Для рукописных букв качество распознавания может быть ниже
   - Старайтесь рисовать буквы похоже на печатные версии

### Параметры обучения:

Все параметры можно изменить в `src/config.py`:
- `LEARNING_RATE = 0.001` - скорость обучения
- `NUM_EPOCHS = 50` - максимальное количество эпох
- `TARGET_ACCURACY = 1.00` - целевая accuracy для ранней остановки (100% = 1.00)
- `BATCH_SIZE = 32` - размер батча
- `TRAIN_VAL_SPLIT = 0.8` - доля данных для обучения (80%)

## Проект завершен

Все основные шаги реализованы:
- ✅ STEP 0-6: Обучение модели с полным пайплайном
- ✅ STEP 7: Предсказания через командную строку
- ✅ STEP 8: Веб-интерфейс (Streamlit) с рисованием
- ✅ STEP 9: Desktop приложение и документация

## Детали реализации

### STEP 1 - Configuration & Utilities

**config.py:**
- Определение путей проекта (data/, models/, etc.)
- Метки классов: `CLASS_LABELS = ["ㄱ", "ㄴ", "ㄷ", "ㄹ", "ㅁ"]`
- Словари для преобразования между метками и индексами
- Функция `get_device()` для автоматического определения CUDA/CPU

**utils.py:**
- `set_seed(seed=42)` - установка seed для воспроизводимости (Python, NumPy, PyTorch, CUDA)
- Функции логирования: `log_info()`, `log_warning()`, `log_error()`

### STEP 2 - Dataset Discovery & Download

**dataset.py:**
- Класс `KoreanAlphabetDataset`, наследующийся от `torch.utils.data.Dataset`
- Функция `download_dataset()` - placeholder для загрузки реального датасета
- Поддержка dummy данных (случайные изображения 28x28) для тестирования структуры
- Методы `__len__()` и `__getitem__()` для работы с данными
- Метод `get_class_name()` для получения метки класса по индексу
- Реальная интеграция данных через генерацию из корейских шрифтов

**config.py (обновлено):**
- Параметры датасета: `IMAGE_SIZE = (28, 28)`, `DEFAULT_NUM_SAMPLES = 1000`

### STEP 3 - Real Dataset Preprocessing

**Генерация через корейские шрифты:**

- `src/datasets/font_based.py` - модуль для работы с корейскими шрифтами:
  - Список `KOREAN_FONTS` - 35+ корейских шрифтов для генерации
  - Функция `find_font_path()` - автоматический поиск шрифтов в системе Windows
  - Функция `generate_korean_char_image()` - генерирует изображения корейских букв используя указанный шрифт
  - Функция `generate_dataset_images()` - создает набор изображений (200 на класс) с разнообразием шрифтов
  - Класс `FontBasedDataset` - загрузка и работа с сгенерированными изображениями

- `src/dataset.py` - основной интерфейс:
  - Класс `KoreanAlphabetDataset` - обертка для работы с датасетом
  - Класс `ImageTransform` - трансформации изображений (resize, grayscale, normalize)
  - Функция `get_dataloaders()` - разделение на train/validation и создание DataLoader'ов

**config.py (обновлено):**
- Параметры: `TRAIN_VAL_SPLIT = 0.8`, `BATCH_SIZE = 32`

**train.py (обновлено):**
- Использование `KoreanAlphabetDataset` для загрузки данных
- Создание train/validation DataLoader'ов
- Вывод информации о форме батчей для проверки

**Структура данных:**
- Изображения сохраняются в `data/raw/<класс>/` (например, `data/raw/ㄱ/`)
- Формат файлов: PNG с именами `{класс}_{шрифт}_{номер}.png`
- Каждое изображение: 28x28 пикселей, grayscale, нормализовано в [-1, 1]
- Разнообразие: каждое изображение генерируется с использованием случайного доступного корейского шрифта

### STEP 4 - CNN Model

**model.py:**
- Класс `KoreanAlphabetCNN` - простая CNN архитектура для классификации корейских букв
- Архитектура:
  - Conv1: 1 канал → 16 каналов, kernel 3x3, padding 1
  - ReLU + MaxPool2d (2x2)
  - Conv2: 16 каналов → 32 канала, kernel 3x3, padding 1
  - ReLU + MaxPool2d (2x2)
  - Flatten
  - FC1: 1568 → 128 нейронов + ReLU
  - FC2: 128 → 5 классов (выходной слой)
- Метод `forward()` - прямой проход через сеть
- Метод `get_num_parameters()` - подсчет количества параметров модели
- Функция `create_model()` - фабричная функция для создания модели

**train.py (обновлено для STEP 4):**
- Создание экземпляра модели через `create_model()`
- Перемещение модели на устройство (GPU/CPU) через `.to(DEVICE)`
- Тестирование forward pass на одном батче
- Вывод информации о модели (количество параметров, устройство)
- Вывод результатов forward pass (форма выходного тензора, предсказания)

**train.py (обновлено для STEP 5):**
- Настройка функции потерь (CrossEntropyLoss) и оптимизатора (Adam)
- Цикл обучения до достижения целевой accuracy (100%) или максимального количества эпох:
  - Forward pass через модель
  - Вычисление loss
  - Backward pass (вычисление градиентов)
  - Обновление весов через optimizer.step()
- Вычисление accuracy после каждой эпохи
- Отслеживание и сохранение лучшей модели
- Ранняя остановка при достижении целевой accuracy

**config.py (обновлено):**
- Параметры обучения: `LEARNING_RATE = 0.001`, `NUM_EPOCHS = 50`, `TARGET_ACCURACY = 1.00` (100%)

**Сохранение моделей:**
- Модели сохраняются в `models/` с именем формата `korean_cnn_best_epoch{N}_acc{X.X}%_YYYYMMDD_HHMMSS.pth`
- Сохраняется только лучшая модель (с наивысшей accuracy)
- Каждый файл содержит: state_dict модели, state_dict оптимизатора, loss, accuracy, метаданные

### STEP 7 - Предсказания

**src/predict.py:**
- Функция `load_model()` - загрузка сохраненной модели с метаданными
- Функция `preprocess_image()` - предобработка изображения (загрузка, трансформации, нормализация)
- Функция `predict()` - выполнение inference на модели
- Функция `find_latest_model()` - автоматический поиск последней обученной модели
- Командная строка интерфейс через `argparse`
- Безопасная обработка ошибок и валидация входных данных
- Читаемый вывод результатов с форматированием

**Использование:**
```powershell
python -m src.predict --image путь/к/изображению.png [--model путь/к/модели.pth]
```

### STEP 8 - Веб-интерфейс (Streamlit)

**ui/app.py:**
- Streamlit веб-приложение для интерактивного распознавания
- Функция `load_cached_model()` - кэшированная загрузка модели (ускоряет работу)
- Два режима работы (вкладки):
  1. **Загрузка файла**: `st.file_uploader()` для загрузки готовых изображений
  2. **Рисование**: `st_canvas()` для интерактивного рисования буквы мышью
- Выбор модели через боковую панель
- Настройки рисования:
  - Настройка толщины линии (1-20 пикселей)
  - Выбор цвета линии (color picker)
  - Кнопка очистки холста
- Визуализация результатов:
  - Отображение загруженного/нарисованного изображения
  - Метрики уверенности
  - Вероятности для всех классов в виде метрик
  - Bar chart вероятностей
- Функция `display_prediction_results()` - общая функция для отображения результатов (используется в обоих режимах)
- Информация о модели и рекомендации

**Технологии:**
- Streamlit для веб-интерфейса
- `streamlit-drawable-canvas` для интерактивного рисования
- Интеграция с функциями из `predict.py`
- Кэширование модели через `@st.cache_resource`
- Локальная работа без внешних зависимостей

**Запуск:**
```powershell
streamlit run ui/app.py
```

### STEP 9 - Desktop приложение

**app_desktop.py:**
- Desktop приложение на CustomTkinter для удобного использования
- Современный интерфейс с темной темой
- Левая панель: настройки модели
  - Выбор модели из списка
  - Статус загрузки модели
  - Информация о модели (эпоха, accuracy, количество классов)
- Правая панель: основная рабочая область
  - Загрузка изображений через файловый диалог
  - Предпросмотр загруженного изображения
  - Кнопка распознавания
  - Отображение результатов с крупным шрифтом
- Многопоточная загрузка модели (не блокирует интерфейс)
- Многопоточное выполнение предсказаний (не блокирует интерфейс)

**Технологии:**
- CustomTkinter для современного GUI
- PIL/Pillow для работы с изображениями
- Интеграция с функциями из `predict.py`
- Автоматическое определение последней модели

**Запуск:**
```powershell
python app_desktop.py
```

## Примечания

- Все комментарии и объяснения на русском языке
- Код разрабатывается инкрементально, каждый шаг должен быть выполнимым
- Модели автоматически сохраняются в директорию `models/`
- Проект автоматически определяет доступность GPU и использует CPU при необходимости
- Seed устанавливается автоматически для обеспечения воспроизводимости результатов
- Предобработка изображений включает автоматическое центрирование содержимого
- Все изображения нормализуются в диапазон [-1, 1] перед подачей в модель

## Итоги проекта

Проект успешно реализует полный пайплайн машинного обучения для распознавания корейских букв:

✅ **Генерация данных** - автоматическая генерация датасета из корейских шрифтов  
✅ **Обучение модели** - полный цикл обучения с метриками и визуализацией  
✅ **Предсказания** - несколько способов использования (CLI, Desktop, Web)  
✅ **Документация** - полная документация всех компонентов  

Модель достигает 100% accuracy на validation наборе и готова к использованию.

