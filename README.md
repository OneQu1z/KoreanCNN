# Распознавание корейских букв с помощью CNN

Проект для обучения сверточной нейронной сети (CNN) на PyTorch для распознавания корейских букв: ㄱ, ㄴ, ㄷ, ㄹ, ㅁ из изображений, включая рукописный ввод.

## Требования

- Python 3.10 или выше
- Windows OS
- NVIDIA GPU с поддержкой CUDA (опционально, но рекомендуется)
- Виртуальное окружение (venv)

## Установка

### 1. Создание виртуального окружения

Откройте PowerShell или командную строку в директории проекта и выполните:

```powershell
python -m venv venv
```

### 2. Активация виртуального окружения

В PowerShell:
```powershell
.\venv\Scripts\Activate.ps1
```

Если возникнет ошибка политики выполнения, выполните:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

В командной строке (cmd):
```cmd
venv\Scripts\activate.bat
```

### 3. Установка зависимостей

```powershell
pip install -r requirements.txt
```

## Запуск

### STEP 0 - Проверка работоспособности

После установки зависимостей выполните:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Сообщение "Training pipeline initialized"
- Информация о доступности CUDA/GPU
- Успешное завершение без ошибок

### STEP 1 - Configuration & Utilities

Запуск аналогичен STEP 0:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Инициализация пайплайна обучения
- Установка seed для воспроизводимости
- Информация о доступности GPU/CUDA
- Информация о классах для распознавания (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ)
- Успешное завершение с сообщением "STEP 1 завершен успешно!"

### STEP 2 - Dataset Discovery & Download

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из STEP 0 и STEP 1
- Инициализация датасета
- Размер датасета (пока используется 1000 dummy сэмплов)
- Размер изображений (28x28)
- Пример сэмпла (shape и метка класса)
- Успешное завершение с сообщением "STEP 2 завершен успешно!"

### STEP 3 - Real Dataset Preprocessing

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Автоматическая генерация реальных изображений корейских букв (если датасет отсутствует)
- Загрузка 1000 реальных изображений (200 для каждого класса)
- Разделение на train/validation (800/200 сэмплов)
- Создание DataLoader'ов для обучения и валидации
- Вывод формы батча: `torch.Size([32, 1, 28, 28])` - 32 изображения, 1 канал (grayscale), 28x28 пикселей
- Нормализация изображений в диапазон [-1, 1]
- Успешное завершение с сообщением "STEP 3 завершен успешно!"

### STEP 4 - CNN Model

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Создание CNN модели (KoreanAlphabetCNN)
- Информация о количестве параметров модели (~206,000)
- Тестирование forward pass на одном батче
- Вывод формы выходного тензора: `torch.Size([32, 5])` - 32 предсказания для 5 классов
- Успешное завершение с сообщением "STEP 4 завершен успешно!"

### STEP 5 - Training Loop

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Настройка обучения (CrossEntropyLoss, Adam optimizer)
- Процесс обучения до достижения целевой accuracy (80%) или максимального количества эпох
- Вывод статистики после каждой эпохи (Loss и Accuracy)
- Сохранение лучшей модели при улучшении accuracy
- Автоматическая остановка при достижении целевой accuracy
- Успешное завершение с сообщением "STEP 5 завершен успешно!"

**Пример результата:** Модель обычно достигает 80%+ accuracy за 2-3 эпохи

### STEP 6 - Metrics & Visualization

Запуск аналогичен предыдущим шагам:

```powershell
python -m src.train
```

Ожидаемый вывод:
- Вся информация из предыдущих шагов
- Создание графиков метрик обучения после завершения обучения
- Сохранение графиков в директорию `plots/`
- Графики содержат:
  - Loss по эпохам (train и validation)
  - Accuracy по эпохам (train и validation)
- Успешное завершение с сообщением "STEP 6 завершен успешно!"

## Структура проекта

```
project/
├── data/
│   ├── raw/              # Исходные данные
│   │   ├── ㄱ/          # Изображения класса ㄱ
│   │   ├── ㄴ/          # Изображения класса ㄴ
│   │   ├── ㄷ/          # Изображения класса ㄷ
│   │   ├── ㄹ/          # Изображения класса ㄹ
│   │   └── ㅁ/          # Изображения класса ㅁ
│   └── processed/        # Обработанные данные
├── models/               # Сохраненные модели
├── plots/                # Графики метрик обучения
├── src/
│   ├── __init__.py
│   ├── config.py         # Конфигурация проекта
│   ├── dataset.py        # Интерфейс для работы с датасетом
│   ├── datasets/         # Модули для работы с данными
│   │   ├── __init__.py
│   │   └── font_based.py    # Генерация через корейские шрифты
│   ├── model.py          # Архитектура CNN
│   ├── train.py          # Обучение модели
│   ├── predict.py        # Предсказания
│   └── utils.py          # Вспомогательные функции
├── ui/                   # Пользовательский интерфейс (будет добавлено)
├── requirements.txt
└── README.md
```

## Источник данных

Проект использует генерацию изображений корейских букв через корейские шрифты, установленные в системе Windows.

### Требования к шрифтам

Для работы проекта необходимо установить корейские шрифты в системе Windows. Проект автоматически ищет следующие шрифты в директории `C:/Windows/Fonts/`:

- BlackAndWhitePicture-Regular
- ChosunIlboMyeongjo
- GamjaFlower-Regular
- GothicA1 (различные варианты: Black, Bold, ExtraBold, ExtraLight, Light, Medium, Regular, SemiBold, Thin)
- HiMelody-Regular
- IropkeBatangM
- NanumBarunGothic, NanumBarunGothic-UltraLight
- NanumBarunPen-Regular
- NanumBrushScript-Regular
- NanumGothic (Bold, ExtraBold, Regular)
- NanumGothicCoding (Bold, Regular)
- NanumMyeongjo (Bold, ExtraBold, Regular)
- NanumPenScript-Regular
- PoorStory-Regular
- SeoulHangang (B, BL, EB, L, M)
- SourceHanSerifK-Regular
- Stylish-Regular

### Генерация данных

При первом запуске проект автоматически:
1. Проверяет наличие установленных корейских шрифтов
2. Генерирует изображения для каждой буквы (ㄱ, ㄴ, ㄷ, ㄹ, ㅁ) используя различные шрифты
3. Сохраняет изображения в директорию `data/raw/<класс>/`

Изображения генерируются с разнообразием:
- Используются все доступные корейские шрифты
- Вариации размера шрифта (20-26 пикселей)
- 200 изображений на класс по умолчанию

## Текущий статус

- **STEP 0** ✅ - Проект инициализирован, базовая структура создана
- **STEP 1** ✅ - Реализованы конфигурация и утилиты:
  - Централизованная конфигурация (`config.py`): пути, метки классов, выбор устройства
  - Вспомогательные утилиты (`utils.py`): установка seed, логирование
  - Обновлен `train.py` для использования config и utils
- **STEP 2** ✅ - Реализована логика работы с датасетом:
  - Класс `KoreanAlphabetDataset` для работы с данными
  - Функция `download_dataset()` для загрузки датасета (пока placeholder)
  - Поддержка dummy данных для тестирования (1000 сэмплов)
  - Интеграция датасета в `train.py`
- **STEP 3** ✅ - Реализована предобработка реальных данных:
  - Генерация изображений через корейские шрифты, установленные в системе
  - Поддержка 35+ корейских шрифтов для разнообразия данных
  - Автоматическое обнаружение доступных шрифтов
  - Предобработка: изменение размера до 28x28, преобразование в grayscale, нормализация
  - Разделение данных на train/validation (80%/20%)
  - Создание DataLoader'ов для батчевой загрузки
  - Проверка и вывод формы батчей
- **STEP 4** ✅ - Реализована CNN модель:
  - Архитектура: 2 сверточных слоя (Conv2d) + 2 полносвязных слоя (Linear)
  - Активации ReLU, MaxPooling для уменьшения размерности
  - Модель для классификации 5 классов корейских букв
  - Forward pass протестирован и работает корректно
  - Модель автоматически размещается на GPU при наличии CUDA
- **STEP 5** ✅ - Реализован цикл обучения:
  - Функция потерь: CrossEntropyLoss
  - Оптимизатор: Adam (learning rate = 0.001)
  - Обучение до достижения целевой accuracy (80%) или максимального количества эпох (50)
  - Вычисление и вывод Loss и Accuracy после каждой эпохи (train и validation)
  - Сохранение лучшей модели при улучшении accuracy (по validation accuracy)
  - Ранняя остановка при достижении целевой accuracy
  - Модель сохраняется с timestamp, accuracy в имени файла и метаданными
- **STEP 6** ✅ - Реализована визуализация метрик:
  - Отслеживание истории loss и accuracy для train и validation наборов
  - Построение графиков с помощью matplotlib
  - Графики loss и accuracy по эпохам
  - Автоматическое сохранение графиков в директорию `plots/`
  - Высокое качество сохранения (DPI 300)
- **STEP 7** ✅ - Реализован скрипт предсказаний:
  - Загрузка сохраненной модели (автоматически находит последнюю или по указанному пути)
  - Загрузка и предобработка изображения (resize, grayscale, normalize)
  - Выполнение inference на модели
  - Вывод предсказанной буквы и уверенности
  - Вывод вероятностей для всех классов
  - Безопасные проверки (существование файлов, обработка ошибок)
  - Читаемый вывод с форматированием

## Следующие шаги

Проект завершен! Все основные шаги реализованы.

- STEP 7: Предсказания на новых данных

## Детали реализации

### STEP 1 - Configuration & Utilities

**config.py:**
- Определение путей проекта (data/, models/, etc.)
- Метки классов: `CLASS_LABELS = ["ㄱ", "ㄴ", "ㄷ", "ㄹ", "ㅁ"]`
- Словари для преобразования между метками и индексами
- Функция `get_device()` для автоматического определения CUDA/CPU

**utils.py:**
- `set_seed(seed=42)` - установка seed для воспроизводимости (Python, NumPy, PyTorch, CUDA)
- Функции логирования: `log_info()`, `log_warning()`, `log_error()`

### STEP 2 - Dataset Discovery & Download

**dataset.py:**
- Класс `KoreanAlphabetDataset`, наследующийся от `torch.utils.data.Dataset`
- Функция `download_dataset()` - placeholder для загрузки реального датасета
- Поддержка dummy данных (случайные изображения 28x28) для тестирования структуры
- Методы `__len__()` и `__getitem__()` для работы с данными
- Метод `get_class_name()` для получения метки класса по индексу
- TODO маркеры для будущей интеграции реальных данных

**config.py (обновлено):**
- Параметры датасета: `IMAGE_SIZE = (28, 28)`, `DEFAULT_NUM_SAMPLES = 1000`

### STEP 3 - Real Dataset Preprocessing

**Генерация через корейские шрифты:**

- `src/datasets/font_based.py` - модуль для работы с корейскими шрифтами:
  - Список `KOREAN_FONTS` - 35+ корейских шрифтов для генерации
  - Функция `find_font_path()` - автоматический поиск шрифтов в системе Windows
  - Функция `generate_korean_char_image()` - генерирует изображения корейских букв используя указанный шрифт
  - Функция `generate_dataset_images()` - создает набор изображений (200 на класс) с разнообразием шрифтов
  - Класс `FontBasedDataset` - загрузка и работа с сгенерированными изображениями

- `src/dataset.py` - основной интерфейс:
  - Класс `KoreanAlphabetDataset` - обертка для работы с датасетом
  - Класс `ImageTransform` - трансформации изображений (resize, grayscale, normalize)
  - Функция `get_dataloaders()` - разделение на train/validation и создание DataLoader'ов

**config.py (обновлено):**
- Параметры: `TRAIN_VAL_SPLIT = 0.8`, `BATCH_SIZE = 32`

**train.py (обновлено):**
- Использование `KoreanAlphabetDataset` для загрузки данных
- Создание train/validation DataLoader'ов
- Вывод информации о форме батчей для проверки

**Структура данных:**
- Изображения сохраняются в `data/raw/<класс>/` (например, `data/raw/ㄱ/`)
- Формат файлов: PNG с именами `{класс}_{шрифт}_{номер}.png`
- Каждое изображение: 28x28 пикселей, grayscale, нормализовано в [-1, 1]
- Разнообразие: каждое изображение генерируется с использованием случайного доступного корейского шрифта

### STEP 4 - CNN Model

**model.py:**
- Класс `KoreanAlphabetCNN` - простая CNN архитектура для классификации корейских букв
- Архитектура:
  - Conv1: 1 канал → 16 каналов, kernel 3x3, padding 1
  - ReLU + MaxPool2d (2x2)
  - Conv2: 16 каналов → 32 канала, kernel 3x3, padding 1
  - ReLU + MaxPool2d (2x2)
  - Flatten
  - FC1: 1568 → 128 нейронов + ReLU
  - FC2: 128 → 5 классов (выходной слой)
- Метод `forward()` - прямой проход через сеть
- Метод `get_num_parameters()` - подсчет количества параметров модели
- Функция `create_model()` - фабричная функция для создания модели

**train.py (обновлено для STEP 4):**
- Создание экземпляра модели через `create_model()`
- Перемещение модели на устройство (GPU/CPU) через `.to(DEVICE)`
- Тестирование forward pass на одном батче
- Вывод информации о модели (количество параметров, устройство)
- Вывод результатов forward pass (форма выходного тензора, предсказания)

**train.py (обновлено для STEP 5):**
- Настройка функции потерь (CrossEntropyLoss) и оптимизатора (Adam)
- Цикл обучения до достижения целевой accuracy (80%) или максимального количества эпох:
  - Forward pass через модель
  - Вычисление loss
  - Backward pass (вычисление градиентов)
  - Обновление весов через optimizer.step()
- Вычисление accuracy после каждой эпохи
- Отслеживание и сохранение лучшей модели
- Ранняя остановка при достижении целевой accuracy

**config.py (обновлено):**
- Параметры обучения: `LEARNING_RATE = 0.001`, `NUM_EPOCHS = 50`, `TARGET_ACCURACY = 0.80`

**Сохранение моделей:**
- Модели сохраняются в `models/` с именем формата `korean_cnn_best_epoch{N}_acc{X.X}%_YYYYMMDD_HHMMSS.pth`
- Сохраняется только лучшая модель (с наивысшей accuracy)
- Каждый файл содержит: state_dict модели, state_dict оптимизатора, loss, accuracy, метаданные

## Примечания

- Все комментарии и объяснения на русском языке
- Код разрабатывается инкрементально, каждый шаг должен быть выполнимым
- Модели автоматически сохраняются в директорию `models/`
- Проект автоматически определяет доступность GPU и использует CPU при необходимости
- Seed устанавливается автоматически для обеспечения воспроизводимости результатов

